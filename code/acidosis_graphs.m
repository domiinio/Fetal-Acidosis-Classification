format compact;
%% best estimator selection

log_reg_data = [0.5436406489028749, 0.6369780667220347, 0.6772766103300459, 0.6862392805972966, 0.6263222840895964, 0.6841514647239428, 0.6894666575530457, 0.6966913632131202, 0.6544281637059535, 0.6381135147704687, 0.6138037717404546, 0.6387261585691552, 0.69688711457775, 0.6490598975852875, 0.6798543498957039, 0.6749099130362943, 0.647328344254696, 0.6268922049194268, 0.6499623928399892, 0.6902455216767065, 0.6480387834781167, 0.636639000066178, 0.6601052272463255, 0.6801022142680004, 0.703297371658999, 0.6903182843313589, 0.6779079371992602, 0.6705418228588125, 0.6857975047049149, 0.6834401516883635, 0.6589844483946646, 0.6717607423363189, 0.6138961202790271, 0.6393095301800106, 0.6887183516040918, 0.6798587554399855, 0.7014733550035215, 0.6303280134957383, 0.7047769337285305, 0.670375829755143, 0.67587641303646, 0.6405931934685496, 0.6703387276676952, 0.6561503012760523, 0.624220777119751, 0.6639793779019186, 0.6469410506366763, 0.7018971511472781, 0.66379937710381, 0.6315643367273145];
svm_data = [0.5809667716698437, 0.6905929651854413, 0.7236619499999146, 0.7348791986436687, 0.7138250246973652, 0.7676643279083659, 0.7563092660329551, 0.6537074073455109, 0.7381401940516745, 0.6788884990794556, 0.720824146491135, 0.7181323021158831, 0.7508597792390537, 0.631597432117316, 0.6842475002553691, 0.7034455776754686, 0.6608437854836607, 0.700282443397012, 0.7119748324769464, 0.758972298406121, 0.705817279665819, 0.6555960503593093, 0.6708426440276242, 0.7339555556935458, 0.6993496352188238, 0.754543190598314, 0.7415847698433967, 0.6740595357133689, 0.6756768015065288, 0.7151404146606755, 0.6180458937719051, 0.7144029157080408, 0.6766827406503091, 0.693366183862613, 0.7094096569708569, 0.6874002881742248, 0.6730353910338014, 0.661293898853072, 0.7437114528808864, 0.7194940651995207, 0.6907147219109936, 0.6980559207964039, 0.6970998071249204, 0.691347090513651, 0.6929178362911097, 0.6875495853114919, 0.7067567716211423, 0.7088770651534482, 0.7037739734052639, 0.6617084421704565];
rf_data = [0.5884031723029469, 0.6341406035332018, 0.6330828619453109, 0.6500899740352194, 0.6806054563162487, 0.6985461293738923, 0.5795004485018656, 0.5965729632885787, 0.6465692438013756, 0.6207963431862592, 0.6431170242990312, 0.6366973779271281, 0.6502135556618561, 0.5680107735701788, 0.6439864234544437, 0.704316373877719, 0.6961433240554563, 0.6014080260584146, 0.6170454222817362, 0.6064912871976851, 0.6180537248348091, 0.5975084103977969, 0.5351603881555764, 0.678897981304271, 0.6361074401691875, 0.6804623681421376, 0.6418905361590534, 0.681970468283088, 0.7241132796870475, 0.6379531559291493, 0.6064032220600973, 0.6005364729904799, 0.6383046957827335, 0.6388622147460392, 0.6107588032844665, 0.711182089237768, 0.640724224774122, 0.6951594192026311, 0.666227925805281, 0.6297408247060219, 0.6753951908942569, 0.6390266750174143, 0.5801704276402444, 0.6658561258027104, 0.59532689889486, 0.6657310236116023, 0.6360932504620956, 0.6476660777157868, 0.704333480148477, 0.563907467408584];
mlp_data = [0.5692454382971973, 0.6217052668539496, 0.652323544165677, 0.6894644044592422, 0.6335474475394695, 0.6731473333807966, 0.6743860892112575, 0.6613169840951353, 0.646145284432437, 0.6289819383269799, 0.6236790512935005, 0.6815108676801623, 0.6942779604734448, 0.637550414147964, 0.6904368357818236, 0.6612652862664686, 0.6279537179933701, 0.6441050001284377, 0.6220716840337843, 0.690698818795512, 0.6333485325236687, 0.56079012450143, 0.6767097570019119, 0.694315200451697, 0.6776507406590724, 0.6673085725622119, 0.6672040844618539, 0.679371576047117, 0.6849573401042407, 0.6705624557644018, 0.6629242621895897, 0.6707349721190333, 0.6130172420613268, 0.6608510112495284, 0.7218840582581468, 0.6625229910354458, 0.7063096263430536, 0.6796152093976229, 0.7104586279216433, 0.6918090930885521, 0.6385249866649186, 0.6654091286683091, 0.6746540139137055, 0.684777819743877, 0.6065475644082051, 0.6505498617608706, 0.6439563956682944, 0.6613045273709618, 0.6703139519272893, 0.6212625619690997];

epochs = 1:1:50;

mean_log_reg = mean(log_reg_data)
mean_svm = mean(svm_data)
mean_rf = mean(rf_data)
mean_mlp = mean(mlp_data)



figure
scatter(epochs,log_reg_data,'r'); hold on;
scatter(epochs,svm_data,'g');
scatter(epochs,rf_data,'b');
scatter(epochs,mlp_data,'c');
plot(0:50, mean_log_reg*ones(size(0:50)),'r','LineWidth',1.2); 
plot(0:50, mean_svm*ones(size(0:50)),'g','LineWidth',1.2);
plot(0:50, mean_rf*ones(size(0:50)),'b','LineWidth',1.2);
plot(0:50, mean_mlp*ones(size(0:50)),'c','LineWidth',1.2);
grid on;
legend()
ylabel('gmean')
xlabel('Test episodes')
title('Comparison of Performance of Individual Classifiers')
legend('Log. Reg.', 'SVM', 'Rand. For.', 'MLP')
%% SVM learning curves

% gamma parameter training errors and testing errors
gammas =  [1e-5,3e-5,7e-5,1e-4,3e-4,7e-4,1e-3,3e-3,7e-3,1e-2,3e-2,7e-2,1e-1,3e-1,7e-1,1e0,1e1];
tr_errors = [0.3725395534055438, 0.3664296603712356, 0.3786773944064329, 0.3568675083098417, 0.35720287588484034, 0.34285154504465176, 0.34164571344136485, 0.29927791361906086, 0.26530233644609746, 0.2458502128798472, 0.1390739698761655, 0.061872600668679056, 0.03290992260708536, 0.007059834650362751, 0.02032142263774661, 0.023258996199224224, 0.28481173606276];
ts_errors = [0.41699902231864827, 0.4188879382508516, 0.48427313927506266, 0.4519869654408296, 0.4628280714481431, 0.37681438279221824, 0.3414352582471101, 0.32484554880004013, 0.31007851948985454, 0.2836068549797728, 0.2549374221063153, 0.32672373105570063, 0.36352847732312754, 0.6166921001378685, 0.661246257052921, 0.818928507914963, 1.0];

semilogx(gammas, tr_errors,'LineWidth',1.2); hold on;
semilogx(gammas, ts_errors,'LineWidth',1.2);
grid on;
legend('Training error', 'Testing error')
xlabel('$\gamma$','interpreter','latex')
ylabel('Error')
title('SVM Learning curve, parameter \gamma')

% C parameter training errors and testing errors
Cs = [1e-5,3e-5,7e-5,1e-4,3e-4,7e-4,1e-3,3e-3,7e-3,1e-2,3e-2,7e-2,1e-1,3e-1,7e-1,1e0,1e1,1e2];
tr_errors = [0.33987585342688087, 0.34416000694435533, 0.34122297627228004, 0.34244160644420896, 0.3381202561479635, 0.3464535755970334, 0.34427379810484016, 0.33579279206355805, 0.3065262632321649, 0.2836070834268535, 0.23345093706473063, 0.17745778314695415, 0.1586008038912352, 0.11572377367451281, 0.06380451384120978, 0.05623035372810836, 0.008893715756646658, 0.0009553174268041031];
ts_errors = [0.376858487173386, 0.3656540385992624, 0.3848329692736864, 0.3656540385992624, 0.3848329692736864, 0.3741184993138059, 0.3741184993138059, 0.37021564606438384, 0.37075409804843096, 0.37031940821253606, 0.33167053725061524, 0.2828914713073899, 0.3287803581300741, 0.2982035224722479, 0.32698181583602914, 0.3408753963978387, 0.38454757205681567, 0.4450891671540125];

figure
semilogx(Cs, tr_errors,'LineWidth',1.2); hold on;
semilogx(Cs, ts_errors,'LineWidth',1.2);
grid on;
legend('Training error', 'Testing error')
xlabel('C')
xlim([1e-5,1e2])
ylabel('Error')
title('SVM Learning curve, parameter C')

%% Random Forest learning curves

% number of estimators errors and time needed
n_estimators = [1,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250,260,270,280,290,300];
tr_errors = [0.09860598554273514, 0.014680291828006675, 0.008458884968005731, 0.00392472647067732, 0.0011306809443164534, 0.0017400395990839757, 0.0035776619049087133, 0.0040983041096234185, 0.0038379489931830157, 0.00392472647067732, 0.004011511508832055, 0.003664416712273133, 0.00392472647067732, 0.0038379489931830157, 0.006640098147487339, 0.006467054003355677, 0.003664416712273133, 0.0006956522581044178, 0.0038379489931830157, 0.0068997208992802594, 0.0037511790743731677, 0.003664416712273133, 0.006467054003355677, 0.0035776619049087133, 0.00095664673809015, 0.003664416712273133, 0.009363893150717617, 0.003404174946495586, 0.003664416712273133, 0.0038379489931830157, 0.0042719120070272565];
ts_errors = [0.43946768598929364, 0.5065499291618218, 0.47022892141827577, 0.4859651773330371, 0.4201007106051017, 0.5030022461733923, 0.4510382170033167, 0.4514701869978147, 0.5018252994432004, 0.45132615921195274, 0.5024788150079667, 0.45132615921195274, 0.46798767998403534, 0.46826731854212833, 0.5201986448817413, 0.484205010798186, 0.5020866027397285, 0.46756849752634344, 0.4511821692237008, 0.48461066952330834, 0.48461066952330834, 0.4511821692237008, 0.467708188333542, 0.46756849752634344, 0.5390217688704053, 0.4674288433593585, 0.5018252994432004, 0.4843401949150935, 0.4843401949150935, 0.48461066952330834, 0.48461066952330834];
times = [0.3523852825164795, 2.2140278816223145, 4.306241273880005, 6.423492193222046, 8.429928541183472, 10.658381462097168, 12.926113367080688, 14.811146974563599, 17.07551407814026, 19.297621726989746, 21.27845072746277, 22.950759410858154, 25.669084310531616, 27.744359493255615, 30.18486189842224, 31.954408884048462, 35.606112241744995, 36.65206265449524, 38.784958839416504, 40.7846417427063, 43.138062715530396, 43.9563193321228, 46.744882583618164, 49.29056668281555, 51.561391830444336, 53.075275897979736, 54.69441056251526, 58.072920083999634, 61.26588463783264, 65.1890799999237, 66.45499801635742];

figure
sgtitle('Random Forest, number of estimators influence')
subplot(2,1,1)
plot(n_estimators, tr_errors,'LineWidth',1.2); hold on;
plot(n_estimators, ts_errors,'LineWidth',1.2);
grid on;
legend('Training error', 'Testing error')
xlabel('n\_estimators')
xlim([1,3e2])
ylabel('Error')
title('Learning curve')
subplot(2,1,2)
plot(n_estimators, times,'LineWidth',1.2); hold on;
xlim([1,3e2])
xlabel('n\_estimators')
ylabel('Computation time [s]')
legend('Training time')
grid on;
title('Time complexity')

% max depth parameter
max_depth = [1,5,10,15,20,25,40,50,60,70,80,90,100,150, 200, 250, 300];
tr_errors = [0.3895111715331053, 0.14436318254163583, 0.040432280241951446, 0.013005034903964874, 0.009617216704918996, 0.004460974232643022, 0.010446800894854724, 0.004895119744443344, 0.004808275490644887, 0.010533153109261062, 0.008229882411378009, 0.005503241863465846, 0.0054163445101490515, 0.0050688309930839726, 0.004027017965240742, 0.00472143881454834, 0.004808275490644887];
ts_errors = [0.3688460859997027, 0.289830810455862, 0.36430926962998544, 0.4477915153437827, 0.4610391469043502, 0.42884741287657835, 0.44319402415487485, 0.4445248596211102, 0.4755955759149242, 0.4443768315997272, 0.4286954499665797, 0.4585948674570405, 0.4755955759149242, 0.42884741287657835, 0.4135422022532127, 0.44275111862878214, 0.4277845199965702];


figure
semilogx(max_depth, tr_errors,'LineWidth',1.2); hold on;
semilogx(max_depth, ts_errors,'LineWidth',1.2);
grid on;
legend('Training error', 'Testing error')
xlabel('max\_depth')
xlim([1,3e2])
ylabel('Error')
title('Random Forest Learning curve, parameter max\_depth')

%% MLP learning curves
% alpha parameter
alphas = [1e-5,3e-5,7e-5,1e-4,3e-4,7e-4,1e-3,3e-3,7e-3,1e-2,3e-2,7e-2,1e-1,3e-1,7e-1,1e0,1e1];
tr_errors = [0.15597366417099057, 0.14210485485499424, 0.16296250132733014, 0.1547007593540637, 0.12709998126611521, 0.1676845026582262, 0.17297116150378455, 0.11828665656862702, 0.15764404545080046, 0.1556887236759863, 0.15125820048392036, 0.15984706605637988, 0.1465801100236772, 0.16434277543557896, 0.1848248532311716, 0.16178615738498525, 0.2946413223064943];
ts_errors = [0.3563066553572456, 0.4617989301037215, 0.35366675359737665, 0.35425246576697966, 0.3920169706972415, 0.4001387604088861, 0.42624650293444966, 0.46676087925747056, 0.44398950715952423, 0.4622297336853449, 0.48675660038522495, 0.44152795718225546, 0.4539466598330847, 0.40499191347910424, 0.41896396343061315, 0.38355706511584275, 0.36994969216123763];

figure
semilogx(alphas, tr_errors,'LineWidth',1.2); hold on;
semilogx(alphas, ts_errors,'LineWidth',1.2);
grid on;
legend('Training error', 'Testing error')
xlabel('\alpha')
xlim([1e-5,1e1])
ylabel('Error')
title('MLP Learning curve, parameter \alpha')

% layer sizes
%(3,32)
gmeans = [0.6391203919888705, 0.5066439038413368, 0.5254993577827648];
disp(mean(gmeans))
%()

